{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect AI Generated Text Using BLSTM & Distilbert\n",
    "[Link](https://www.kaggle.com/code/shahbodsobhkhiz/detect-ai-generated-text-using-blstm-distilbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#plot tools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#simple tools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'D:/NTHU_NLP_2024_Term_Project_35/'\n",
    "train_essays = pd.read_csv(f'{DATA_PATH}/train_essays.csv')\n",
    "#train_65 = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text-dataset/Training_Essay_Data.csv')\n",
    "train_65 = pd.read_csv(f'{DATA_PATH}/Training_Essay_Data.csv')\n",
    "#prompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')\n",
    "prompts = pd.read_csv(f'{DATA_PATH}/train_prompts.csv')\n",
    "#original = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n",
    "original = pd.read_csv(f'{DATA_PATh}/train_essays.csv')\n",
    "#train_v2 = pd.read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')\n",
    "train_v2 = pd.read_csv(f'{DATA_PATh}/train_v2_drcat_02.csv')\n",
    "\n",
    "#train_lim = pd.read_csv('/kaggle/input/llm-generated-essays/ai_generated_train_essays.csv')\n",
    "train_lim = pd.read_csv(f'{DATA_PATh}/ai_generated_train_essays.csv')\n",
    "#train_lim2 = pd.read_csv('/kaggle/input/llm-generated-essays/ai_generated_train_essays_gpt-4.csv')\n",
    "train_lim2 = pd.read_csv(f'{DATA_PATh}/ai_generated_train_essays_gpt-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the datasets: \n",
    "combined_from_comp = pd.merge(original,prompts, on='prompt_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new column order\n",
    "new_column_order = ['id', 'prompt_id' , 'prompt_name', 'instructions', 'source_text', 'text', 'generated']\n",
    "\n",
    "# Reorder the columns\n",
    "combined_from_comp = combined_from_comp[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim = pd.concat([train_lim, train_lim2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels distribution:\", np.bincount(train_lim['generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels distribution:\", np.bincount(combined_from_comp['generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_from_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "prompt_mapping = {\n",
    "    0: 'car-free-cities',\n",
    "    1: 'Does the electoral college work?'\n",
    "}\n",
    "instructions = {\n",
    "    0 : 'Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.',\n",
    "    1 : 'Write a letter to your state senator in which you argue in favor of keeping the Electoral College or changing to election by popular vote for the president of the United States. Use the information from the texts in your essay. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to include a claim; address counterclaims; use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your response in the space provided.'    \n",
    "}\n",
    "source_text = {\n",
    "    0 : str(combined_from_comp['instructions'].unique()[0]),\n",
    "    1 : str(combined_from_comp['instructions'].unique()[1])\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the new column\n",
    "train_lim['prompt_name'] = train_lim['prompt_id'].map(prompt_mapping)\n",
    "train_lim['source_text'] = train_lim['prompt_id'].map(source_text)\n",
    "train_lim['instructions'] = train_lim['prompt_id'].map(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim = train_lim[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = pd.concat([combined_from_comp,train_lim],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels distribution:\", np.bincount(train_merged['generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = train_merged[['text' , 'generated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v2 = train_v2[['text' , 'label']]\n",
    "train_v2.rename(columns = {'label' : 'generated'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged2 = pd.concat([train_v2,train_65] , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = pd.concat([train_merged , train_merged2] , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.bincount(train_merged['generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame\n",
    "train_merged = train_merged.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_merged = train_merged.head(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels distribution:\", np.bincount(train_merged['generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged['word_count'] = train_merged['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Calculate the statistics\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x=train_merged['word_count'])\n",
    "plt.title('Violin Plot of Word Count per Tweet')\n",
    "plt.xlabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = train_merged.drop('word_count', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels distribution:\", np.bincount(train_merged['generated']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balacing the data labels here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming 'train_merged' is your DataFrame and 'generated' is the label column\n",
    "majority_class = train_merged[train_merged['generated'] == 0]\n",
    "minority_class = train_merged[train_merged['generated'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the majority class\n",
    "majority_downsampled = resample(majority_class,\n",
    "                                replace=False,  # Sample without replacement\n",
    "                                n_samples=len(minority_class),  # Match the number of minority class\n",
    "                                random_state=42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = pd.concat([majority_downsampled, minority_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels distribution:\", np.bincount(train_merged['generated']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split into train+val and test\n",
    "train_val_df, test_df = train_test_split(train_merged, test_size=0.1, random_state=42, stratify=train_merged['generated'])\n",
    "\n",
    "# Now, split the train+val into train and validation\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.1, random_state=42, stratify=train_val_df['generated'])\n",
    "\n",
    "# Print the sizes of the splits to verify\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_df['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encodings and labels into TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_df['generated'].tolist()))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings), val_df['generated'].tolist()))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_df['generated'].tolist()))\n",
    "\n",
    "# Batch the datasets\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset)).batch(8)\n",
    "val_dataset = val_dataset.batch(16)\n",
    "test_dataset = test_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 2)\n",
    "\n",
    "# Compile the model\n",
    "class DistilBertWithDropout(tf.keras.Model):\n",
    "    def __init__(self, base_model, num_labels, dropout_rate=0.3):\n",
    "        super(DistilBertWithDropout, self).__init__()\n",
    "        self.base_model = base_model  # Assign the base_model correctly\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.classifier = tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        outputs = self.base_model(inputs)\n",
    "        \n",
    "        if len(outputs[0].shape) == 3:\n",
    "            # Assume the output is [batch_size, sequence_length, hidden_size]\n",
    "            pooled_output = outputs[0][:, 0, :]  # Extract the [CLS] token's output\n",
    "        elif len(outputs[0].shape) == 2:\n",
    "            # Assume the output is [batch_size, hidden_size] directly\n",
    "            pooled_output = outputs[0]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected output shape from the base model.\")\n",
    "        \n",
    "        dropout_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(dropout_output)\n",
    "        return logits\n",
    "\n",
    "# Instantiate the model\n",
    "num_labels = 2  # Adjust this depending on your number of classes\n",
    "dropout_rate = 0.3  # You can adjust the dropout rate\n",
    "model = DistilBertWithDropout(model, num_labels, dropout_rate)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"best_model\", save_best_only=True, save_format='tf')\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=4,  # You can set this to a higher number\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of accuracy results on training and validation data\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Retrieve a list of loss results on training and validation data\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get the number of epochs\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "# Plot training and validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "# Since the model outputs logits, convert these to predicted class labels\n",
    "y_pred_labels = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels from the test set\n",
    "y_true = []\n",
    "for _, labels in test_dataset:\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Convert to a TensorFlow tensor for compatibility\n",
    "y_true = tf.convert_to_tensor(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Manually define the class labels if not available in the model config\n",
    "class_labels = ['negative', 'positive']  # Replace with your actual class names\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the custom model\n",
    "model.save('./AI-detector', save_format='tf')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('./AI-detector-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('./AI-detector')\n",
    "\n",
    "loaded_tokenizer = DistilBertTokenizer.from_pretrained('./AI-detector-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['generated'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "Embedding_dimensions = 150\n",
    "\n",
    "# Creating Word2Vec training dataset.\n",
    "Word2vec_train_data = list(map(lambda x: x.split(), train_df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model and training it.\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=Word2vec_train_data,  # The tokenized training data\n",
    "    vector_size=Embedding_dimensions,  # Size of the embedding vectors\n",
    "    window=5,  # Maximum distance between the current and predicted word within a sentence\n",
    "    min_count=5,  # Ignores all words with total frequency lower than this\n",
    "    workers=8,  # Number of CPU cores to use for training\n",
    "    sg=0  # Use Skip-Gram model (sg=1), or CBOW model (sg=0)\n",
    ")\n",
    "\n",
    "print(\"Vocabulary Length:\", len(word2vec_model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 512\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = 20000\n",
    "\n",
    "tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<oov>\")\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "tokenizer.num_words = vocab_length\n",
    "print(\"Tokenizer vocab length:\", vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_df['text']), maxlen=input_length)\n",
    "X_test  = pad_sequences(tokenizer.texts_to_sequences(test_df['text']) , maxlen=input_length)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"X_test.shape :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_word_index = {word: token for word, token in tokenizer.word_index.items() if token <= vocab_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_length , Embedding_dimensions))\n",
    "\n",
    "for word, token in filtered_word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[token] = word2vec_model.wv[word]\n",
    "\n",
    "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Dense, LSTM, Conv1D, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    embedding_layer = Embedding(input_dim = vocab_length,\n",
    "                                output_dim = Embedding_dimensions,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=input_length,\n",
    "                                trainable=False)\n",
    "\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
    "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
    "        Conv1D(100, 5, activation='relu'),\n",
    "        GlobalMaxPool1D(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"Sentiment_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = getModel()\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "             EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = training_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc,  val_acc  = history.history['accuracy'], history.history['val_accuracy']\n",
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def ConfusionMatrix(y_pred, y_test):\n",
    "    # Compute and plot the Confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    categories  = ['Negative','Positive']\n",
    "    group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    "                xticklabels = categories, yticklabels = categories)\n",
    "\n",
    "    plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.ylabel(\"Actual values\"   , fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df['text']\n",
    "y_test = test_df['generated']\n",
    "\n",
    "# Tokenize and pad the test data\n",
    "X_test_sequences = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=input_length)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = training_model.predict(X_test_sequences)\n",
    "\n",
    "# Convert prediction probabilities to binary outcomes (0 or 1)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "\n",
    "# Print the confusion matrix\n",
    "ConfusionMatrix(y_pred, y_test)\n",
    "\n",
    "# Additionally, print the classification report for detailed metrics\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the BiLSTM model\n",
    "training_model.save('saved_bilstm_model.keras')\n",
    "\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save('word2vec_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_bilstm_model = load_model('saved_bilstm_model.keras')\n",
    "loaded_word2vec_model = Word2Vec.load('word2vec_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_essay = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(test_essay['text'].tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TensorFlow dataset only for these 3 entries\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_encodings)).batch(8)\n",
    "\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert logits to probabilities using softmax\n",
    "prediction_probabilities = tf.nn.softmax(predictions.logits, axis=-1).numpy()\n",
    "\n",
    "# Extract the probability of the positive class\n",
    "positive_class_probs = prediction_probabilities[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of test_essay['id']: {len(test_essay['id'])}\")\n",
    "print(f\"Length of positive_class_probs: {len(positive_class_probs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'id': test_essay['id'],\n",
    "    'generated': positive_class_probs\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
