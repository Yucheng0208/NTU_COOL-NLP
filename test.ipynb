{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合嵌入特徵到分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字嵌入處理\n",
    "train_embeddings = model.encode(train_df['text'].tolist(), show_progress_bar=True)\n",
    "val_embeddings = model.encode(val_df['text'].tolist(), show_progress_bar=True)\n",
    "test_embeddings = model.encode(test_df['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "train_embeddings = scaler.fit_transform(train_embeddings)\n",
    "val_embeddings = scaler.transform(val_embeddings)\n",
    "test_embeddings = scaler.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將嵌入特徵添加到 BERT 編碼中\n",
    "train_encodings['additional_features'] = tf.convert_to_tensor(train_embeddings)\n",
    "val_encodings['additional_features'] = tf.convert_to_tensor(val_embeddings)\n",
    "test_encodings['additional_features'] = tf.convert_to_tensor(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改模型結構以接受額外特徵\n",
    "class CombinedModel(tf.keras.Model):\n",
    "    def __init__(self, base_model, num_labels, embedding_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.additional_dense = tf.keras.layers.Dense(embedding_dim, activation='relu')\n",
    "        self.concat_layer = tf.keras.layers.Concatenate()\n",
    "        self.classifier = tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        base_output = self.base_model(inputs)\n",
    "        additional_features = self.additional_dense(inputs['additional_features'])\n",
    "        combined_output = self.concat_layer([base_output, additional_features])\n",
    "        return self.classifier(combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = CombinedModel(model, num_labels=2, embedding_dim=train_embeddings.shape[1])\n",
    "combined_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多模型結果融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 透過預測結果進行融合\n",
    "bert_predictions = model.predict(test_dataset)\n",
    "bilstm_predictions = training_model.predict(X_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 投票融合\n",
    "final_predictions = (bert_predictions + bilstm_predictions) / 2\n",
    "final_predictions = np.round(final_predictions).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 t-SNE 可視化分類結果\n",
    "embeddings_tsne = TSNE(n_components=2, random_state=42).fit_transform(train_embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label in np.unique(train_df['generated']):\n",
    "    idx = train_df['generated'] == label\n",
    "    plt.scatter(embeddings_tsne[idx, 0], embeddings_tsne[idx, 1], label=f'Class {label}')\n",
    "plt.legend()\n",
    "plt.title('t-SNE Visualization of Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合後的結果\n",
    "1. BERT 模型與 SentenceTransformer 結合，提高分類模型對文字特徵的感知能力。\n",
    "2. 降維後的視覺化提供分類結果的直觀解釋。\n",
    "3. 多模型融合有效減少單一模型偏差的風險。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
